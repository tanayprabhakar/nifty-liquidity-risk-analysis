{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5d47b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "     ---------------------------------------- 0.0/123.4 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 30.7/123.4 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 30.7/123.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 123.4/123.4 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting peewee>=3.16.2\n",
      "  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/3.0 MB 3.2 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.3/3.0 MB 5.2 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 0.6/3.0 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.0/3.0 MB 6.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.6/3.0 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 2.0/3.0 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 2.0/3.0 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 2.0/3.0 MB 9.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 2.7/3.0 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 8.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting curl_cffi>=0.7\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     --------------------- ------------------ 0.9/1.6 MB 27.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.1/1.6 MB 17.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.6 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.4/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.4/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.4/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting protobuf>=3.19.0\n",
      "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
      "     ---------------------------------------- 0.0/436.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 436.9/436.9 kB 26.7 MB/s eta 0:00:00\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytz>=2022.5\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     ---------------------------------------- 0.0/509.2 kB ? eta -:--:--\n",
      "     ---------------------------------- -- 471.0/509.2 kB 14.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- 509.2/509.2 kB 10.8 MB/s eta 0:00:00\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.4.7-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Collecting pandas>=1.3.0\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "     ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/11.3 MB 4.0 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.3/11.3 MB 4.9 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.3/11.3 MB 4.9 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.1/11.3 MB 7.2 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.3/11.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.9/11.3 MB 8.0 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.4/11.3 MB 9.0 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 2.6/11.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 3.1/11.3 MB 9.1 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 3.6/11.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 3.6/11.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 3.7/11.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 3.7/11.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 3.7/11.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 3.9/11.3 MB 6.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.6/11.3 MB 8.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 5.8/11.3 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 6.4/11.3 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 6.9/11.3 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.0/11.3 MB 8.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 7.4/11.3 MB 8.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.9/11.3 MB 8.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 8.4/11.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.5/11.3 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.7/11.3 MB 8.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 9.2/11.3 MB 8.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 9.4/11.3 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.9/11.3 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 10.3/11.3 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.6/11.3 MB 9.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  11.2/11.3 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 11.3/11.3 MB 8.8 MB/s eta 0:00:00\n",
      "Collecting requests>=2.31\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 0.0/64.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 64.7/64.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yfinance) (2.2.6)\n",
      "Collecting websockets>=13.0\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "     ---------------------------------------- 0.0/176.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 176.8/176.8 kB 11.1 MB/s eta 0:00:00\n",
      "Collecting beautifulsoup4>=4.11.1\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "     ---------------------------------------- 0.0/106.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 106.4/106.4 kB 6.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Collecting cffi>=1.12.0\n",
      "  Downloading cffi-2.0.0-cp310-cp310-win_amd64.whl (182 kB)\n",
      "     ---------------------------------------- 0.0/182.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 182.8/182.8 kB 10.8 MB/s eta 0:00:00\n",
      "Collecting certifi>=2024.2.2\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "     ---------------------------------------- 0.0/159.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 159.4/159.4 kB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     ---------------------------------------- 0.0/347.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 347.8/347.8 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)\n",
      "     ---------------------------------------- 0.0/107.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 107.2/107.2 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 0.0/71.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.0/71.0 kB ? eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "     ---------------------------------------- 0.0/129.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 129.8/129.8 kB 7.5 MB/s eta 0:00:00\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 0.0/118.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 118.1/118.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.3-py3-none-any.whl size=139181 sha256=93f4f4604f32d90a3dc8da101fdde08787b9dbbfd98a682baaa4237bda1cc21e\n",
      "  Stored in directory: c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\3d\\96\\39\\80c50cbf6bd446cdca9dac7d78a1a0d3a1f313859500529f8d\n",
      "Successfully built peewee\n",
      "Installing collected packages: pytz, peewee, multitasking, websockets, urllib3, tzdata, soupsieve, pycparser, protobuf, idna, frozendict, charset_normalizer, certifi, requests, pandas, cffi, beautifulsoup4, curl_cffi, yfinance\n",
      "  Running setup.py install for multitasking: started\n",
      "  Running setup.py install for multitasking: finished with status 'done'\n",
      "Successfully installed beautifulsoup4-4.14.2 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 curl_cffi-0.13.0 frozendict-2.4.7 idna-3.11 multitasking-0.0.12 pandas-2.3.3 peewee-3.18.3 protobuf-6.33.1 pycparser-2.23 pytz-2025.2 requests-2.32.5 soupsieve-2.8 tzdata-2025.2 urllib3-2.5.0 websockets-15.0.1 yfinance-0.2.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: multitasking is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tanay\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2905bcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads...\n",
      "\n",
      "Downloading NIFTY_50 (^NSEI)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_50.csv\n",
      "\n",
      "Downloading NIFTY_BANK (^NSEBANK)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_BANK.csv\n",
      "\n",
      "Downloading NIFTY_IT (^CNXIT)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_IT.csv\n",
      "\n",
      "Downloading NIFTY_FMCG (^CNXFMCG)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_FMCG.csv\n",
      "\n",
      "Downloading NIFTY_AUTO (^CNXAUTO)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_AUTO.csv\n",
      "\n",
      "Downloading NIFTY_REALTY (^CNXREALTY)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_REALTY.csv\n",
      "\n",
      "Downloading NIFTY_METAL (^CNXMETAL)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_METAL.csv\n",
      "\n",
      "Downloading NIFTY_PHARMA (^CNXPHARMA)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_PHARMA.csv\n",
      "\n",
      "Downloading NIFTY_PSU_BANK (^CNXPSUBANK)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_PSU_BANK.csv\n",
      "\n",
      "Downloading NIFTY_ENERGY (^CNXENERGY)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_27544\\984258366.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIFTY_ENERGY.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# Date range\n",
    "start = \"2015-01-01\"\n",
    "end = date.today().isoformat()\n",
    "\n",
    "# Yahoo Finance tickers for NIFTY sectoral indices\n",
    "tickers = {\n",
    "    \"NIFTY_50\": \"^NSEI\",\n",
    "    \"NIFTY_BANK\": \"^NSEBANK\",\n",
    "    \"NIFTY_IT\": \"^CNXIT\",\n",
    "    \"NIFTY_FMCG\": \"^CNXFMCG\",\n",
    "    \"NIFTY_AUTO\": \"^CNXAUTO\",\n",
    "    \"NIFTY_REALTY\": \"^CNXREALTY\",\n",
    "    \"NIFTY_METAL\": \"^CNXMETAL\",\n",
    "    \"NIFTY_PHARMA\": \"^CNXPHARMA\",\n",
    "    \"NIFTY_PSU_BANK\": \"^CNXPSUBANK\",\n",
    "    \"NIFTY_ENERGY\": \"^CNXENERGY\"\n",
    "}\n",
    "\n",
    "print(\"Starting downloads...\\n\")\n",
    "\n",
    "for name, ticker in tickers.items():\n",
    "    print(f\"Downloading {name} ({ticker})...\")\n",
    "    df = yf.download(ticker, start=start, end=end, progress=False)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"⚠️ WARNING: No data for {ticker}.\")\n",
    "        continue\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df.to_csv(f\"{name}.csv\", index=False)\n",
    "    print(f\"Saved {name}.csv\\n\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65341b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.32.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanay\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tanay\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df6e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing connection with NSE...\n",
      "Fetching 840 days of data. Please wait...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# --- RUN THE SCRIPT ---\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m df_gap \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_nse_gap_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_gap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_gap\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccess! Fetched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_gap)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 86\u001b[0m, in \u001b[0;36mfetch_nse_gap_data\u001b[1;34m(start_str, end_str)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m \u001b[38;5;66;03m# Skip empty days or errors\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# IMPORTANT: Sleep to prevent blocking\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# 4. Create DataFrame and Save\u001b[39;00m\n\u001b[0;32m     89\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_rows)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "start_date = \"01-09-2022\"  # Start from where your Kaggle data ended\n",
    "end_date = datetime.now().strftime(\"%d-%m-%Y\") # Up to today\n",
    "\n",
    "def fetch_nse_gap_data(start_str, end_str):\n",
    "    # 1. Setup Session and Headers (Critical to avoid getting HTML)\n",
    "    session = requests.Session()\n",
    "    head = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'referer': 'https://www.nseindia.com/reports/fii-dii'\n",
    "    }\n",
    "\n",
    "    # 2. Visit Homepage to initialize Cookies (The \"Ticket\" to get data)\n",
    "    print(\"Initializing connection with NSE...\")\n",
    "    try:\n",
    "        session.get(\"https://www.nseindia.com\", headers=head, timeout=20)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not connect to NSE: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 3. Generate list of dates\n",
    "    s_dt = pd.to_datetime(start_str, format=\"%d-%m-%Y\")\n",
    "    e_dt = pd.to_datetime(end_str, format=\"%d-%m-%Y\")\n",
    "    business_days = pd.bdate_range(s_dt, e_dt)\n",
    "\n",
    "    print(f\"Fetching {len(business_days)} days of data. Please wait...\")\n",
    "    \n",
    "    all_rows = []\n",
    "\n",
    "    for date_obj in business_days:\n",
    "        d_str = date_obj.strftime(\"%d-%m-%Y\")\n",
    "        \n",
    "        # THE MAGIC API URL (Not the website URL)\n",
    "        api_url = f\"https://www.nseindia.com/api/fiidiiArchives?category=capital-market&date={d_str}\"\n",
    "        \n",
    "        try:\n",
    "            response = session.get(api_url, headers=head, timeout=5)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json() # Expecting JSON, not HTML\n",
    "                \n",
    "                # The API returns a list. We need to find FII and DII items.\n",
    "                # Structure varies, usually list of dicts\n",
    "                fii_data = None\n",
    "                dii_data = None\n",
    "                \n",
    "                for item in data:\n",
    "                    if \"FII\" in item['category'] or \"FPI\" in item['category']:\n",
    "                        fii_data = item\n",
    "                    elif \"DII\" in item['category']:\n",
    "                        dii_data = item\n",
    "                \n",
    "                if fii_data and dii_data:\n",
    "                    # Clean the numbers (remove commas)\n",
    "                    fii_buy = float(fii_data['buyValue'].replace(',', ''))\n",
    "                    fii_sell = float(fii_data['sellValue'].replace(',', ''))\n",
    "                    dii_buy = float(dii_data['buyValue'].replace(',', ''))\n",
    "                    dii_sell = float(dii_data['sellValue'].replace(',', ''))\n",
    "                    \n",
    "                    row = {\n",
    "                        'Date': date_obj.strftime('%d-%b-%Y'), # Matches typical Kaggle format\n",
    "                        'FII Buy': fii_buy,\n",
    "                        'FII Sell': fii_sell,\n",
    "                        'FII Net': fii_buy - fii_sell,\n",
    "                        'DII Buy': dii_buy,\n",
    "                        'DII Sell': dii_sell,\n",
    "                        'DII Net': dii_buy - dii_sell\n",
    "                    }\n",
    "                    all_rows.append(row)\n",
    "                    print(f\"Fetched: {d_str} | FII Net: {row['FII Net']:.2f}\", end='\\r')\n",
    "            \n",
    "            else:\n",
    "                # If session expires, refresh it\n",
    "                session.get(\"https://www.nseindia.com\", headers=head)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass # Skip empty days or errors\n",
    "        \n",
    "        # IMPORTANT: Sleep to prevent blocking\n",
    "        time.sleep(1) \n",
    "\n",
    "    # 4. Create DataFrame and Save\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    "\n",
    "# --- RUN THE SCRIPT ---\n",
    "df_gap = fetch_nse_gap_data(start_date, end_date)\n",
    "\n",
    "if df_gap is not None and not df_gap.empty:\n",
    "    print(f\"\\n\\nSuccess! Fetched {len(df_gap)} rows.\")\n",
    "    filename = \"FII_DII_Gap_Data_Sep22_Present.csv\"\n",
    "    df_gap.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to: {filename}\")\n",
    "else:\n",
    "    print(\"\\nNo data found. NSE might be blocking the connection or market is closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
